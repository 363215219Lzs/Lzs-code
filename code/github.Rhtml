<html>

<head>
<title>BCMC-code</title>
</head>

<body>
<p>1. Assume the parameters of survival function and true value</p>
<!--begin.rcode
##1.1 set observation intervals 
k<-260
interval<-1
a<- seq(0,interval*k,interval)
#2.set transition roads
m<-4
s<-c(1:m)
#s<-1#PFS_PD
#s<-2#PD_PFS
#s<-3#PFS_D
#s<-4#PD_D

##3.Assume the baseline survival function parameters: lamda, alpha for the transition  
lamda_pfs<-0.2
alpha_pfs<-1.2
lamda_pd<-0.2
alpha_pd<-0.9
s_pfs<-exp(-lamda_pfs*((a/10)^alpha_pfs))
s_pd<-exp(-lamda_pd*((a/10)^alpha_pd))

#4.Assume beta
X<-1#The value of the covav riate, 1 represents the intervention
beta<- matrix(0, nrow=m, ncol=k)
#1. Constant
for(t in 1:k){
  beta[1,t]<-(-log(2))
  beta[2,t]<-log(2)
  beta[3,t]<-(-log(2))
  beta[4,t]<-(-log(2))
}

write.csv(beta[,1:(k)],"~/Desktop/beta_true_con.csv")


#2. Monotonic
beta<- matrix(0, nrow=m, ncol=k)
for(t in 1:k){
  beta[1,t]<-(-3.5)+log(t/20+15)#
  beta[2,t]<-4-log(t/10+25)
  beta[3,t]<-(-3.5)+log(t/20+15)
  beta[4,t]<-(-3.5)+log(t/20+15)
}

write.csv(beta,"~/Desktop/beta_true_var.csv")
#3.U-shaped 
beta<- matrix(0, nrow=m, ncol=k)
  for(t in 1:k){
    x<-t
  si<-60
  mu<-130
  beta[1,t]<-(-1)*40*si^(-1)*exp((-(x-130)^2)/(2*si^2))#
  beta[2,t]<-45*si^(-1)*exp((-(x-130)^2)/(2*si^2))
  beta[3,t]<-(-1)*40*si^(-1)*exp((-(x-130)^2)/(2*si^2))#
  beta[4,t]<-(-1)*40*si^(-1)*exp((-(x-130)^2)/(2*si^2))#
  }
 write.csv(beta,"~/Desktop/beta_true_norm.csv")
 
HR<- matrix(0, nrow=m, ncol=k)
HR<-exp(beta)

plot(1:k, HR[1,][1:k], type="l", col="green3", ylim=c(0,3), xlab="Time", ylab="HR", main="Dynamic HR (True value)",bty ="l",lwd=2)
lines(1:k, HR[2,][1:k], type="l", col="orange",lwd=2)
lines(1:k, rep(1,k)[1:k], lty=2, col="red",lwd=2)
legend("topright", legend=c("Other paths", "PD-PFS","HR=1"), col=c("green3", "orange", "red"), bty ="n",lty=1, ,lwd=2,cex=0.8)


#Definite test group
s_pfs_tr<-c(s_pfs[1],s_pfs[-1]^(exp(X*beta[1,])))
s_pd_tr<-c(s_pd[1],s_pd[-1]^(exp(X*beta[2,])))
end.rcode-->

<p>2. Generate the transition probability matrix<p>
<!--begin.rcode
library(expm)
library(pracma)
#  generate transition probability matrixs of k periods
p_list <- c(rep(NA, 3*3*k))
dim(p_list)<-c(3,3,k)
for (t in 1:k) {
  p <- matrix(0, nrow = 3, ncol = 3)  
  col_names <-c("PFS","PD","D")
  row_names <- c("PFS","PD","D")
  p[1,1]<-s_pfs[t+1]/s_pfs[t]
  p[1,3]<-0.001
  p[1,2]<-max((1-p[1,1]-p[1,3]),0)
  p[2,2]<-s_pd[t+1]/s_pd[t]
  p[2,3]<-0.002
  p[2,1]<-max((1-p[2,2]-p[2,3]),0)
  p[3,1]<-0
  p[3,2]<-0
  p[3,3]<-1
  p_list[,,t] <- p  
}

plot(1:k, p_list[1,2,1:k], type="l", col="steelblue2", ylim=c(0,0.08), xlab="Time", ylab="P", main="Probability",bty ="l",lwd=2)
lines(1:k, p_list[2,1,1:k], type="l", col="purple",lwd=2)
lines(1:k, p_list[1,3,1:k], type="l", col="palegreen3",lwd=2)
lines(1:k, p_list[2,3,1:k], type="l", col="gold1",lwd=2)
legend("topright", legend=c("PFS-PD", "PD-PFS","PFS-D","PD-D"), col=c("steelblue2", "purple", "palegreen3", "gold1"), lty=1, ,lwd=2,cex=0.8, bty = "n")

# simulated the period of 1-8 weeks, 56 points were inserted
e<-7
int<-c((1:56)/7,9:k)
length(int)

library(pracma)
p_list_ste<- c(rep(0, 3*3*length(int)))
dim(p_list_ste)<-c(3,3,length(int))
for(i in 1:8){
  p_list_ste[,,((i-1)*7+1):((i-1)*7+7)]<-abs(sqrtm(sqrtm(sqrtm(p_list[,,1])$B)$B)$B)
}
p_list_ste[,,57:length(int)]<-p_list[,,9:k]


#treatment group
X<-1
p_list_tr <- c(rep(0, 3*3*(k)))
dim(p_list_tr)<-c(3,3,(k))
for (t in 1:(k)) {
  p <- matrix(0, nrow = 3, ncol = 3)  
  col_names <-c("PFS","PD","D")
  row_names <- c("PFS","PD","D")
  p[1,3]<-0.001*(exp(X*beta[3,t]))
  p[1,1]<-s_pfs_tr[t+1]/s_pfs_tr[t]#alpha=1，=exp(-lamda)
  p[1,2]<-max(1-p[1,1]-p[1,3],0)
  p[2,3]<-0.002*(exp(X*beta[4,t]))
  p[2,2]<-s_pd_tr[t+1]/s_pd_tr[t]
  p[2,1]<-max((1-p[2,2]-p[2,3]),0)
  p[3,1]<-0
  p[3,2]<-0
  p[3,3]<-1
  p_list_tr[,,t] <- p 
}

plot(1:(k), p_list_tr[1,2,1:(k)], type="l", col="steelblue2", ylim=c(0,0.08), xlab="Time", ylab="P", main="Probability",bty ="l",lwd=2)
lines(1:(k), p_list_tr[2,1,1:(k)], type="l", col="purple",lwd=2)
lines(1:(k), p_list_tr[1,3,1:(k)], type="l", col="palegreen3",lwd=2)
lines(1:(k), p_list_tr[2,3,1:(k)], type="l", col="gold1",lwd=2)
legend("topright", legend=c("PFS-PD", "PD-PFS","PFS-D","PD-D"), col=c("steelblue2", "purple", "palegreen3", "gold1"), lty=1,lwd=2, cex=0.8, bty = "n")

# simulated the period of 1-8 weeks, 56 points were inserted
e<-7
int<-c((1:56)/7,9:(k))
p_list_tr_ste<- c(rep(0, 3*3*length(int)))
dim(p_list_tr_ste)<-c(3,3,length(int))
for(i in 1:8){
  p_list_tr_ste[,,((i-1)*7+1):((i-1)*7+7)]<-abs(sqrtm(sqrtm(sqrtm(p_list_tr[,,i])$B)$B)$B)
}
p_list_tr_ste[,,57:length(int)]<-p_list_tr[,,9:(k)]
end.rcode-->

<p>3.Simulate the state transition<p>
<!--begin.rcode
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
states<- 3  # number of states
n<-5000 # The number of samples 
k<-260# the number of loops
int<-c((1:56)/7,9:(k))
n.cores <- detectCores()
n.cores
cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
#1. Repeat the cycle to generate sample data _ control group
data<-foreach(i = 1:n,
               .combine = rbind,
               .errorhandling = "pass") %dopar% {
  current_state <- rep(1:2,each=n/2)[1]
  da<-c(current_state)
  # Store sample sequences
  for(t in 1:length(int)){
    next_state <- sample(1:states, 1, prob = p_list_ste[current_state,,t])
  da<- c(da,next_state)
  current_state<-next_state
  }
  return(da)
               }
data_1  <- as.data.frame(data)
colnames(data_1)<-c(1:(length(int)+1))

#1. Repeat the cycle to generate sample data _ treatment group
data<-foreach(i = 1:n,
               .combine = rbind,
               .errorhandling = "pass") %dopar% {
  current_state <- rep(1:2,each=n/2)[1]
  da<-c(current_state)
  # Store sample sequences
  for(t in 1:length(int)){
    next_state <- sample(1:states, 1, prob = p_list_tr_ste[current_state,,t])
  da<- c(da,next_state)
  current_state<-next_state
  }
  return(da)
               }
stopCluster(cl)
data_2  <- as.data.frame(data)
colnames(data_2)<-c(1:(length(int)+1))

data_tran<- c(rep(0, n*(length(int)+1)*2))
dim(data_tran)<-c(n,(length(int)+1),2)
data_tran[,,1]<-as.matrix(data_1)
data_tran[,,2]<-as.matrix(data_2)
write.csv(data_tran,"~/Desktop/data_tran_con.csv")#_con,_var,_norm
end.rcode-->

<p>4. Extracted  survival time data<p>
<!--begin.rcode
Time<-c(rep(1, (length(int)+1)))
s<-c(rep(0, (length(int)+1)))
data<-data_tran
cl <- makeCluster(8-1) 
registerDoParallel(cl)
c_1<-foreach(i = 1:n,
               .combine = rbind,
               .errorhandling = "pass") %dopar% {
                 c<-c(rep(0, 6))
for(dat in 1:2){
for(t in 1:length(int)){
  #survival time t
  Time[t+1]<-ifelse(data[i,t,dat]==data[i,t+1,dat],Time[t]+1,1)
  #state transition m
  if ((data[i,t,dat]==1)&(data[i,t+1,dat]==2)) {s[t]<-1}
  else if ((data[i,t,dat]==2)&(data[i,t+1,dat]==1)) {s[t]<-2}
  else if ((data[i,t,dat]==1)&(data[i,t+1,dat]==3)) {s[t]<-3} 
  else if ((data[i,t,dat]==2)&(data[i,t+1,dat]==3)) {s[t]<-4}
  else s[t]<-0
  }
 #chain data
if (any(s != 0)==TRUE) {
    if(Time[length(int)+1]==1){
  for(l in 1:(sum(s!= 0))){
    ci<-c(ID=i,y=Time[which(s!= 0)][l],m=s[which(s!= 0)][l],"k"=which(s!= 0)[l],X=dat-1,sigema=1)
    c<-as.data.frame(rbind(c,ci))
  }
    }
    if(Time[length(int)+1]>1){
     for(l in 1:(sum(s!= 0))){
   ci1<-c(ID=i,y=Time[which(s!= 0)][l],m=s[which(s!= 0)][l],"k"=which(s!= 0)[l],X=dat-1,sigema=1)
   c<-as.data.frame(rbind(c,ci1))
     }
    if(data[i,length(int)+1,dat]==1|data[i,length(int)+1,dat]==2){
   ci2<-c(ID=i,y=Time[length(int)+1]-1,m=data[i,length(int)+1,dat],"k"=length(int),X=dat-1,sigema=0)
    c<-as.data.frame(rbind(c,ci2))
  }
      if(data[i,length(int)+1,dat]==3){
  c<-c
     }
    }
     }#If t[k+1] is greater than 1 and is not in state 3, then the survival time of the individual in state 1/2 is the censoring data and the survival time is t[k+1]-1
 if (any(s!= 0)==FALSE) {
  ci<-c(ID=i,y=length(int),m=data[i,length(int)+1,dat],"k"=length(int),X=dat-1,sigema=0)
    c<-as.data.frame(rbind(c,ci))
   }
}
                 return(c)
}
stopCluster(cl)
C<-as.data.frame(c_1[which(!c_1$ID==0),])
d<-sort(unique(C$y))
write.csv(C,"~/Desktop/C_sample_con.csv")#_con,_var,_norm
end.rcode-->

<p>5. BCMC<p>
<p>5.1 Prior data<p>
<!--begin.rcode
library(rjags)
install.packages('coda')
library(coda)
# Load  data
c<-6#c("ID","t","m","j","X","sigema")
l<-0
m<-4
for(m in 1:4){
len1<-length(which(C$m==m))
l<-c(l,len1)
}
l<-l[-1]
sum(l)
row<-max(l)
Y<-c(rep(NA, row*c*m))
dim(Y)<-c(row,c,m)
colnames(Y) <-c("ID","t","m","j","X","sigema")
for(m in 1:4){
  len1<-length(which(C$m==m))
 Y[1:len1,,m]<-as.matrix(C[which(C$m==m),])
}
# Dimension of vector d is k
a <- 0
d<-c(1:length(int))
for(j in 2:length(d)){
a[j] <- (d[j-1] + d[j])/2
}
a[j+1] <- d[j] + (d[j] - d[j-1])/2
end.rcode-->

<p>5.2 Bayesian Estimation<p>
<!--begin.rcode
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
library(R2jags)
library(coda)
library(lattice)
library(MCMCvis)
#j=1
m<-4
j<-1
Y2<-Y[,2,]
delta<-Y[,6,]
interval<-1

h<-matrix(0,max(l),m)
nn<-matrix(0,max(l),m)
for(m in 1:4){
for(i in 1:l[m]){
h0<- ifelse(Y2[i,m]*interval < a[j],0,1)
aa0<-ifelse(Y2[i,m]*interval > a[j+1],0,1)
h[i,m]<-h0*(min(Y2[i,m]*interval,a[j+1])-a[j])
nn[i,m]<-h0*aa0*delta[i,m]
}
}

Y1<-Y[,5,]
lam<-matrix(0,m,length(int))
beta<-matrix(0,m,length(int))
lam1<-lam[,j]
beta1<-beta[,j]

model_string <- textConnection("
  model{
# Likelihood Construction
for(m in 1:4){
for(i in 1:l[m]){
nn[i,m]~ dpois(exp(beta1[m]*(Y1[i,m]))*h[i,m]*lam1[m])
}}

  # Prior for lambdas
lamm <- 10000*(0.01) # exp(-a[2]*0.01) = 0.995
for(m in 1:4){
lam1[m] ~ dgamma(lamm,10000)#j=1
}

# Inferences for the HRs and prior on the betas
# relative hazard
for(m in 1:4){
beta1[m] ~ dnorm(0,0.000001)
}# 
}
")
data_list <- list(l=l,Y1=Y1,h=h,nn=nn)
m<-4
inits <- list(beta1=rnorm(m),lam1=rep(0.1,m))
model <- jags.model(model_string,data = data_list, inits=inits, n.chains=2,n.adapt=1000)
#(4)generate 20000 post-burn-in samples
params <- c("beta1")#,"lam","S.pos","S.neg","S.diff") 
sample <- coda.samples(model,variable.names=params,n.iter=20000, progress.bar="none")#
#(5)Summarize the output
sum<-summary(sample)
beta_post0_con<-cbind(mean=sum[["statistics"]][,1],lwr=sum[["quantiles"]][,1],upr=sum[["quantiles"]][,5])

#~~~~~
m<-4
f<-rep(0,m)
e<-rep(0,m)
lam<-matrix(0,m,length(int))
beta<-matrix(0,m,length(int))
cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
Y2<-Y[,2,]
delta<-Y[,6,]
Y1<-Y[,5,]
beta_post1_con<-foreach(j = 2:length(int),
               .combine = rbind,
              .packages = c("R2jags","coda","lattice","MCMCvis"),
               .errorhandling = "pass") %dopar% {
#1.data list
lam1<-lam[,j]
beta1<-beta[,j]

h<-matrix(0,max(l),m)
nn<-matrix(0,max(l),m)
for(m in 1:4){
for(i in 1:l[m]){
h0<- ifelse(Y2[i,m]*interval < a[j],0,1)
aa0<-ifelse(Y2[i,m]*interval > a[j+1],0,1)
h[i,m]<-h0*(min(Y2[i,m]*interval,a[j+1])-a[j])
nn[i,m]<-h0*aa0*delta[i,m]
}
}
a1<-a[j+1]-a[j]
#2.constrcut model
model_string <- textConnection("
  model{
# Likelihood Construction
for(m in 1:4){
for(i in 1:l[m]){
nn[i,m]~ dpois(exp(beta1[m]*(Y1[i,m]))*h[i,m]*lam1[m])
}}

  # Prior for lambdas
lamstar <- 0.05# Select value or set prior for lamstar
w<-0.01
# lamstar ~ dgamma(a,ww) a=0.05*ww ww=0.01
for(m in 1:4){
# prior on baseline hazard bits
f[m] <- w*a1
e[m] <- lamstar*f[m]
lam1[m] ~ dgamma(e[m],f[m])
}

# Inferences for the HRs and prior on the betas
# relative hazard
for(m in 1:4){
beta1[m] ~ dnorm(0,0.000001)
} 
}")
data_list <- list(l=l,Y1=Y1,h=h,nn=nn,a1=a1)
m<-4
inits <- list(beta1=rnorm(m),lam1=rep(0.1,m))
model <- jags.model(model_string,data = data_list, inits=inits, n.chains=2,n.adapt=1000)
#(4)generate 20000 post-burn-in samples
params <- c("beta1")#,"lam","S.pos","S.neg","S.diff") 
#params <- c("HR")
sample <- coda.samples(model,variable.names=params,n.iter=20000, progress.bar="none")#很快2min
# (5) Summarize the output
sum<-summary(sample)
outcome<-as.data.frame(cbind(mean=sum[["statistics"]][,1],lwr=sum[["quantiles"]][,1],upr=sum[["quantiles"]][,5]))#差别不大
return(outcome3)
}
stopCluster(cl)

beta_post_1<-as.data.frame(rbind(beta_post0_con,beta_post1_con))
write.csv(beta_post_1,"~/Desktop/beta_bcmc_con.csv")#_con,_var,_norm
end.rcode-->

<p>6. fre-cox<p>
<!--begin.rcode
m<-4 
HR_Fre<-matrix(0,m,3)
library(survival)
for(m in c(1:4)){
  data0<-C[which(C$m==m),]
  data<-list(y=data0$y,group=data0$X,delta=data0$sigema)
  res.cox <- coxph(Surv(y, delta) ~ group, data = data)
  sum<-summary(res.cox)
  HR_Fre[m,]<-cbind(sum$coefficients[2],sum$conf.int[3],sum$conf.int[4])
}

colnames(HR_Fre)<-c("HR","low","upr")
write.csv(HR_Fre,"~/Desktop/HR_fre_con.csv")#_con,_var,_norm
end.rcode-->

<p>7. time-varying cox (contimuous function)<p>
<!--begin.rcode
install.packages(c("survival", "survminer"))
library("survival")
library("survminer")
HR_TV<-matrix(0,length(int),m)
HR_TV_low<-matrix(0,length(int),m)
HR_TV_upr<-matrix(0,length(int),m)

for(m in c(1:4)){ 
  data<-list(y=Y[,2,m],group=Y[,5,m],delta=Y[,6,m])
  fit<- coxph(Surv(y, delta) ~ group+tt(group), data = data,tt =function(x,int,...) x * log(int))
  sum<-summary(fit)
 HR_TV[,m]<-exp(sum$coefficients[1,1]+sum$coefficients[2,1]*log(int))
 HR_TV_low[,m]<-exp(log(sum$conf.int[1,3])+log(sum$conf.int[2,3])*log(int))
 HR_TV_upr[,m]<-exp(log(sum$conf.int[1,4])+log(sum$conf.int[2,4])*log(int))
}

HR_TV<-cbind(HR_TV,HR_TV_low,HR_TV_upr)
write.csv(HR_TV,"~/Desktop/HR_TV_con.csv")#_con,_var,_norm
end.rcode-->

<p>8.regularize and fit Estimated value<p>
<p>8.1 Filter,Normalize,Average  <p>
<!--begin.rcode
beta_post_1<- read_csv("~/Desktop/beta_bcmc_con.csv")
HR_cox <- read_csv("~/Desktop/HR_fre_con.csv")[,-1]
HR_TV <- read_csv("~/Desktop/HR_TV_con.csv")[,-1]
beta <- read_csv("~/Desktop/beta_true_con.csv")[,-1]
beta_post_11<-c(beta_post_1$mean,beta_post_1$upr)
x<-c(0:(length(int)*2))
beta_post<-as.data.frame(x)
be<-c(0)
for(m in 1:4){
  for(t in 1:(length(int)*2)){
  row<-m+4*(t-1)
  be<-c(be,beta_post_11[row])#mean
  }
  beta_post<-cbind(beta_post,be)
  be<-c(0)
}
beta_post<-beta_post[-1,]
colnames(beta_post)<-c("x","y1","y2","y3","y4")
summary(beta_post)
dim(beta_post)
beta_post$y1f<-beta_post$y1
beta_post$y2f<-beta_post$y2
beta_post$y3f<-beta_post$y3
beta_post$y4f<-beta_post$y4

fan<-cbind(1:length(int),(1:length(int))+length(int))
for(m in 1:4){
ci<-beta_post[fan[,2],m+1]-beta_post[fan[,1],m+1]
ci[which(ci>3)]<-3
beta_post[fan[,2],m+5]<-ci
}
summary(beta_post[fan[,2],])
#Removal of extremes
for(m in 1:4){
  up<-quantile(beta_post[fan[,1],m+1], 0.975)
  lw<-quantile(beta_post[fan[,1],m+1], 0.025)
for(t in fan[-1,1]){
  beta_post[t,m+5]<-ifelse(beta_post[t,m+1]<=up&beta_post[t,m+1]>=lw,beta_post[t,m+1],beta_post[t-1,m+5])
}
  }

#normalization
stan1<-HR_cox[4,1]
redu<-abs(log(stan1)/mean(beta_post$y4f[fan[,1]]))
for(m in c(1,3,4)){
  direction<-ifelse(mean(beta_post[fan[,1],m+5])<0,1,(-1))
  beta_post[fan[,1],m+5]<-beta_post[fan[,1],m+5]*redu*direction
}
  m<-2
  direction<-ifelse(mean(beta_post[fan[,1],m+5])>0,1,(-1))
beta_post[fan[,1],m+5]<-beta_post[fan[,1],m+5]*redu*direction
#for beta
for(l in 1:2){  
for(m in 1:4){
for(t in fan[,l]){
  beta_post[t,m+9]<-(mean(beta_post[(max(min(fan[,l]),(t-5))):(min(max(fan[,l]),(t+5))),m+5]/2))
}
}
}
plot(int, beta_post$V10[fan[,1]], type="l", col="steelblue2" , xlab="Weeks",ylab="beta",ylim=c(-4,4),main="Time-varying beta (After filtering)",bty="l",lwd=1)#range(beta_post$V10,na.rm=TRUE)
lines(int, beta_post$V11[fan[,1]], type="l", col="purple",lwd=1)
lines(int, beta_post$V12[fan[,1]], type="l", col="palegreen3",lwd=1)
lines(int, beta_post$V13[fan[,1]], type="l", col="gold1",lwd=1)
lines(int, rep(0,length(int)), lty=2, col="black",lwd=1)
legend("topright", legend=c("PFS-PD", "PD-PFS", "PFS-D", "PD-D","beta=0"), col=c("steelblue1", "purple", "palegreen3", "gold1","black"), lty=c(1,1,1,1,2), cex=0.8,lwd=1.5,bty="n")

beta_post<-beta_post[,10:13]
write.csv(beta_post,"~/Desktop/beta_stan_con.csv")
end.rcode-->

<p>8.2 weibull fit and 95%CI<p>
<!--begin.rcode
#weibull fit
library(readr)
beta_post <-read_csv("~/Desktop/beta_stan_con.csv")[,-1]
staus<-c("var")#con,var,norm
bcmc_wei<-list()
length(int)
fan<-cbind(1:length(int),(1:length(int))+length(int))
library (MASS)
for(m in 1:4){
fit_num<-c((1:8)*7,57:length(int))
y1<-beta_post[fan[,1],m]
y0<-exp(y1)
y_fit<-data.frame(matrix(0,k,3))
y<-y0[fit_num]
 if ((m==1)|(m==3)|(m==4)) {y[which(y>1)]<-1}
   if (m==2) {y[which(y<1)]<-1}
y<-y-1
inter<-1
redu<-sum(y)*inter/2
y<-y/redu
sum(y*inter)#=1
X<-sample(1:(k)-0.5,10000,prob=y,replace = TRUE)
fit<-fitdistr(X, "Weibull")
shape<-fit[["estimate"]][1]
scale<-fit[["estimate"]][2]
t<-c(1:k)
fitting<-dweibull(t, shape = shape, scale = scale)
y_fit[,1]<-fitting*(redu)+1
if((m==1)){plot(t, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
lines(t,rep(0.5,260))
if((m==2)|(m==3)|(m==4)){lines(t, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
bcmc_wei[[m]]<-y_fit
}

#95%ci
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
z<-1.96
n0<-2500
staus<-c("con")
staus<-c("var")
staus<-c("norm")
dat_all<-list()
for(m in 1:4){
y_95<-matrix(NA,nrow=n0,ncol=length(int))
mean<-exp(beta_post[fan[,1],m])
upr<-exp(beta_post[fan[,1],m]+beta_post[fan[,2],m])
sd0<-(upr-mean)/z*((n0)^(1/2))
for(col in 1:length(int)){
y_95[,col]<-rnorm(n0,mean=as.numeric(mean[col]),sd=as.numeric(sd0[col]))
}
fitting<-matrix(NA,nrow=n0,ncol=k)
  cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
fitting<-foreach(nn = 1:n0,
               .combine = rbind,
               .packages = c("MASS"),
               .errorhandling = "pass") %dopar% {
                 y<-y_95[nn,fit_num]
   base<-1+mean(y)-mean(as.vector(mean[1])[[1]])
  if ((m==1)|(m==3)|(m==4)) {y[which(y>base)]<-base}
 if (m==2) {y[which(y<base)]<-base}
y<-y-base
inter<-1
redu<-sum(y)*inter/1
y<-y/redu
sum(y*inter)#=1
length(y)
X<-sample(1:(k),10000,prob=y,replace = TRUE)
fit<-fitdistr(X, "Weibull")
shape<-fit[["estimate"]][1]
scale<-fit[["estimate"]][2]
t<-c(1:k)
weibull<-dweibull(t, shape = shape, scale = scale)
#plot(weibull)
#lines(weibull)
weibull<-weibull*(redu)+base
return(weibull)
}
stopCluster(cl)
y_upr<-c()
y_lwr<-c()
  for(col in 1:(k)){
  fitt<-as.numeric(unlist((fitting[,col])))
y_upr[col]<-quantile(fitt, 0.975,na.rm=TRUE)
y_lwr[col]<-quantile(fitt, 0.025,na.rm=TRUE)
  }
stan<-(bcmc_wei[[m]][,1]-1)/((y_upr+y_lwr)/2-1)
y_upr_1<-(y_upr-1)*stan+1
y_lwr_1<-(y_lwr-1)*stan+1
t<-1:(k)
plot(t, bcmc_wei[[m]][,1], type="l", col="steelblue2", ylim=c(0,3), xlab="Week", ylab="beta", main="Time-varying beta")
lines(t,y_upr_1,type="l")
lines(t,y_lwr_1,type="l")
lines(t,rep(0.5,k),type="l")
bcmc_wei[[m]][,2]<-y_upr_1
bcmc_wei[[m]][,3]<-y_lwr_1
min(y_lwr)
colnames(bcmc_wei[[m]])<-c("bcmc","bcmc_lwr","bcmc_upr")
y_cox<-cbind(rep(HR_cox[m,1],length(t)),rep(HR_cox[m,2],length(t)),rep(HR_cox[m,3],length(t)))
colnames(y_cox)<-c("cox","cox_lwr","cox_upr")
y_tv<-cbind(HR_TV[,m],HR_TV[,m+4],HR_TV[,m+8])[c((1:8)*7,57:308),]
colnames(y_tv)<-c("tv","tv_lwr","tv_upr")
y_true<-t(exp(beta[m,]))
x<- data.frame(x = t)
dat_all[[m]]<-cbind(x,bcmc_wei[[m]],y_cox,y_tv,y_true)
}
dat_weibull<-dat_all
end.rcode-->

<p>8.3 linear fit and 95%ci<p>
<!--begin.rcode
#linear fit
library(readr)
beta_post <- read_csv("~/Desktop/beta_stan_con.csv")[,-1]
library (MASS)
bcmc_lin<-list()
y_fit<-data.frame(matrix(0,length(int),3))
for(m in 1:4){
y1<-beta_post[fan[,1],m]
y0<-exp(y1)
dat_fit<-as.data.frame(cbind(y0,int))
colnames(dat_fit)<-c("y0","int")
fit<-lm(y0~int,data=dat_fit)
y_fit[,1]<-fitted(fit)
if((m==1)){plot(int, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
lines(t,rep(0.5,260))
if((m==2)|(m==3)|(m==4)){lines(int, y_fit[,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")}
bcmc_lin[[m]]<-y_fit[fit_num,]
}

z<-1.96
n0<-2500
dat_all<-list()
for(m in 1:4){
y_95<-matrix(NA,nrow=n0,ncol=length(int))
mean<-exp(beta_post[fan[,1],m])
upr<-exp(beta_post[fan[,1],m]+beta_post[fan[,2],m])
sd0<-(upr-mean)/z*((n0)^(1/2))
for(col in 1:length(int)){
y_95[,col]<-rnorm(n0,mean=as.numeric(mean[col]),sd=as.numeric(sd0[col]))
}
fitting<-matrix(NA,nrow=n0,ncol=k)
  cl <- makeCluster(n.cores-1) 
registerDoParallel(cl)
fitting<-foreach(nn = 1:n0,
               .combine = rbind,
               .packages = c("MASS"),
               .errorhandling = "pass") %dopar% {
                 y1<-y_95[nn,]
y0<-y1
dat_fit<-as.data.frame(cbind(y0,int))
colnames(dat_fit)<-c("y0","int")
fit<-lm(y0~int,data=dat_fit)
fitted<-fitted(fit)[fit_num]
return(fitted)
}
stopCluster(cl)
  for(col in 1:(k)){
  fitt<-as.numeric(unlist((fitting[,col])))
y_upr[col]<-quantile(fitt, 0.975,na.rm=TRUE)
y_lwr[col]<-quantile(fitt, 0.025,na.rm=TRUE)
  }
base_1<-max(bcmc_lin[[m]][,1])
#base_2<-min(bcmc_lin[[m]][,1])
stan_1<-(bcmc_lin[[m]][,1]-base_1)/((y_upr)+(y_lwr)/2-base_1)
#stan_2<-(bcmc_lin[[m]][,1]-base_2)/((y_upr)+(y_lwr)/2-base_2)
#stan<-(bcmc_lin[[m]][,1])/((y_upr)+(y_lwr)/2)
y_upr_1<-(y_upr-base_1)*stan_1+base_1
y_lwr_1<-bcmc_lin[[m]][,1]*2-y_upr_1
#m<-1,0.2
t<-1:(k)
plot(t, bcmc_lin[[m]][,1], type="l", col="steelblue2", ylim=c(0,4), xlab="Week", ylab="beta", main="Time-varying beta")
lines(t,y_upr_1,type="l")
lines(t,y_lwr_1,type="l")
lines(t,rep(1,k),type="l")
bcmc_lin[[m]][,2]<-y_upr_1
bcmc_lin[[m]][,3]<-y_lwr_1
colnames(bcmc[[m]])<-c("bcmc","bcmc_lwr","bcmc_upr")
y_cox<-cbind(rep(HR_cox[m,1],length(t)),rep(HR_cox[m,2],length(t)),rep(HR_cox[m,3],length(t)))
colnames(y_cox)<-c("cox","cox_lwr","cox_upr")
y_tv<-cbind(HR_TV[,m],HR_TV[,m+4],HR_TV[,m+8])[fit_num,]
colnames(y_tv)<-c("tv","tv_lwr","tv_upr")
y_true<-t(exp(beta[m,]))
x<- data.frame(x = t)
dat_all[[m]]<-cbind(x,bcmc_lin[[m]],y_cox,y_tv,y_true)
}     
dat_linear<-dat_all
end.rcode-->

<p>8.4 select better fitting model<p>
<!--begin.rcode
for(m in 1:4){
dat_lin<-dat_linear[[m]]
dat_wei<-dat_weibull[[m]]
origin<-beta_post[fan[,1],m][fit_num,]
mse_1<-(dat_lin$bcmc-exp(origin))^2
mse_2<-(dat_wei$bcmc-exp(origin))^2
print(mean(mse_1[,1]))
print(mean(mse_2[,1]))
dat_all[[m]][,2:4]<-ifelse(mse_1<mse_2,dat_lin[,2:4],dat_wei[,2:4])
}
write.csv(dat_all,"~/Desktop/HR_ALL_con.csv")
end.rcode-->

<p>9. Table_1<p>
<!--begin.rcode
library(readr)
dat_con<- read_csv("~/Desktop/HR_ALL_con.csv")[,-1]
dat_var<- read_csv("~/Desktop/HR_ALL_var.csv")[,-1]
dat_norm<- read_csv("~/Desktop/HR_ALL_norm.csv")[,-1]
mae<-0
mse<-0
mape<-0
mae_5<-0
mse_5<-0
dat<-as.data.frame(0)
for(m in 1:4){
  dat<-dat_draw[,c((m-1)*11+2,(m-1)*11+5,(m-1)*11+8,(m-1)*11+11)]
  colnames(dat)<-c("bcmc","cox","tv","true")
  a<-mean(abs(dat$true-dat$cox))
  b<-mean(abs(dat$true-dat$tv))
  c<-mean(abs(dat$true-dat$bcmc),na.rm = TRUE)
  mae<-c(mae,a,b,c)
  d<-mean((dat$true-dat$cox)^2)
  e<-mean((dat$true-dat$tv)^2)
  f<-mean((dat$true-dat$bcmc)^2,na.rm = TRUE)
  mse<-c(mse,d,e,f)
  g<-paste0(mean(abs((dat$true-dat$cox)/dat$true))*100,"%")
  h<-paste0(mean(abs((dat$true-dat$tv)/dat$true))*100,"%")
  j<-paste0(mean(abs((dat$true-dat$bcmc)/dat$true),na.rm = TRUE)*100,"%")
  mape<-c(mape,g,h,j)
  #k<-paste0("(",round(t.test(abs(dat$true-dat$cox))$conf.int[1],2),",",round(t.test(abs(dat$true-dat$cox))$conf.int[2],2),")")
  k<-0#for constant
  l<-paste0("(",round(t.test(abs(dat$true-dat$tv))$conf.int[1],2),",",round(t.test(abs(dat$true-dat$tv))$conf.int[2],2),")")
  m<-paste0("(",round(t.test(abs(dat$true-dat$bcmc))$conf.int[1],2),",",round(t.test(abs(dat$true-dat$bcmc))$conf.int[2],2),")")
  mae_5<-c(mae_5,k,l,m)
  #n<-paste0("(",round(t.test((dat$true-dat$cox)^2)$conf.int[1],2),",",round(t.test((dat$true-dat$cox)^2)$conf.int[2],2),")")
   n<-0#for constant
  o<-paste0("(",round(t.test((dat$true-dat$tv)^2)$conf.int[1],2),",",round(t.test((dat$true-dat$tv)^2)$conf.int[2],2),")")
  p<-paste0("(",round(t.test((dat$true-dat$bcmc)^2)$conf.int[1],2),",",round(t.test((dat$true-dat$bcmc)^2)$conf.int[2],2),")")
 mse_5<-c(mse_5,n,o,p)
  }
rmse<-sqrt(mse)
out_con<-cbind(mae,mae_5,mse,mse_5,rmse,mape)[-1,]
out_var<-cbind(mae,mae_5,mse,mse_5,rmse,mape)[-1,]
out_norm<-cbind(mae,mae_5,mse,mse_5,rmse,mape)[-1,]

write.csv(out_con,"~/Desktop/table1_con_z.csv")
write.csv(out_var,"~/Desktop/table1_var_z.csv")
write.csv(out_norm,"~/Desktop/table1_norm_z.csv")
end.rcode-->

<p>10. Table_2<p>
<!--begin.rcode
t<-c(1:(k))
dat_norm<-dat_draw
a<-t[which.min(dat_norm$bcmc...3)]
b<-t[which.max(dat_norm$bcmc...14)]
c<-t[which.min(dat_norm$bcmc...25)]
d<-t[which.min(dat_norm$bcmc...36)]

top<-c(k/2,a,b,c,d)
top
os_norm<-c(0)
for(k in top){
  p_list_tr_var <- p_list
  p_list_tr_var[,,(1:k)]<-p_list_tr[,,(1:k)]
data_var <- as.data.frame(0, nrow = n, ncol = 260+1)
for(i in 1:n){
  current_state <- rep(1:2,each=n/2)[i]
  data_var[i,1] <- c(current_state)  # Store sample sequences
  for(t in 1:260){
    next_state <- sample(1:states, 1, prob = p_list_tr_var[current_state,,t])
  data_var[i,t+1] <- c(as.numeric(next_state))
  current_state<-next_state
  }
}
h<-c(1:k)
os<-apply(data_var,1,function(x){h[which(x==3)[1]]})
os_norm<-cbind(os_norm,os)
}
os_norm<-os_norm[,-1]
summary(os_norm)
OS_NORM_2<-c(0)
for(c in 1:5){
 mean<-mean(os_norm[,c],na.rm =TRUE)
 mean_low<-t.test(os_norm[,c])$conf.int[1]
 mean_up<-t.test(os_norm[,c])$conf.int[2]
 os<-paste0(round(mean/4,2),"(",round(mean_low/4,2),"~",round(mean_up/4,2),")")
 OS_NORM_2<-cbind(OS_NORM_2,c(mean,mean_low,mean_up,os))
}
colnames(OS_NORM_2)
OS_NORM_2<-rbind(top,OS_NORM_2[,-1])
write.csv(OS_NORM_2,"~/Desktop/table2_norm_z.csv")
end.rcode-->

<p>11. constant freeplot<p>
<!--begin.rcode
library(readr)
dat_con<- read_csv("~/Desktop/HR_ALL_con.csv")[,-1]

esti<-c()
for(m in 1:4){
  dat<-dat_con[,c(((m-1)*11+2),((m-1)*11+5):((m-1)*11+8),((m-1)*11+11))]
  colnames(dat)<-c("bcmc","cox","cox_lwr","cox_upr","tv","true")
  a0<-dat$true[1]
  a<-c(dat$cox[1],dat$cox_lwr[1],dat$cox_upr[1])
  b<-c(mean(dat$tv),quantile(dat$tv, 0.025),quantile(dat$tv, 0.975))
  c<-c(mean(dat$bcmc),quantile(dat$bcmc, 0.025),quantile(dat$bcmc, 0.975))
  esti<-rbind(esti,a0,a,b,c)
}
 esti<-as.data.frame(esti)
esti$ES_95<-paste0(round(esti[,1],2)," (",round(esti[,2],2),", ",round(esti[,3],2),")")

write.csv(esti,"~/Desktop/table2_con_z.csv")
end.rcode-->

<p>12. TVC-Cox(B splines)<p>
<!--begin.rcode
dat_all<-list()
library(readr)
dat_draw <- read_csv("~/Desktop/HR_ALL_norm.csv")[,-1]
for(m in 1:4){
  dat_all[[m]]<-dat_draw[,((m-1)*11+1):((m-1)*11+14)]
  colnames(dat_all[[m]])<-c("x","bcmc","bcmc_lwr","bcmc_upr","cox","cox_lwr","cox_upr","tv","tv_lwr","tv_upr","y_true")
}
  m<-1
  m<-2
  data<-data.frame(y=Y[,2,m],group=Y[,5,m],delta=Y[,6,m],tp=Y[,4,m])[1:l[m],]
fit[[m]]<-fitSmoothHazard(delta~group*ns(tp,df=3),
                    data=data,time="y")
m<-3
  data<-data.frame(y=Y[,2,m],group=Y[,5,m],delta=Y[,6,m],tp=Y[,4,m])[1:l[m],]
for(m1 in 1){
  data_1<-data.frame(y=Y[,2,m1],group=Y[,5,m1],delta=0,tp=Y[,4,m1])[1:l[m1],]
  data<-rbind(data,data_1)
}
  table(data$delta)
  table(data$y,data$delta)
fit[[m]]<-fitSmoothHazard(delta~group*ns(tp,df=4),
                    data=data,time="y")

m<-4
data<-data.frame(y=Y[,2,m],group=Y[,5,m],delta=Y[,6,m],tp=Y[,4,m])[1:l[m],]
for(m1 in 2){
  data_1<-data.frame(y=Y[,2,m1],group=Y[,5,m1],delta=0,tp=Y[,4,m1])[1:l[m1],]
  data<-rbind(data,data_1)
}
  table(data$delta)
  table(data$y,data$delta)
fit[[m]]<-fitSmoothHazard(delta~group*ns(tp,df=4),
                    data=data,time="y")

dat_rcs<-list()
newtime=c(1:260)
newdata1=data.frame(group=factor("1",levels=c("1","0")),tp=newtime)
for(m in 1:4){
p1<-plot(fit[[m]],newdata=newdata1,var="group",increment=1,xvar="tp",type="hr",ci=T)
rcs<-data.frame(TVC=p1$hazard_ratio,TVC_lwr=p1$lowerbound,TVC_upr=p1$upperbound)
dat_rcs[[m]]<-cbind(dat_all[[m]],rcs)
}
write.csv(dat_rcs,"~/Desktop/HR_TVC_ALL_norm.csv")
end.rcode-->

</body>
</html>
